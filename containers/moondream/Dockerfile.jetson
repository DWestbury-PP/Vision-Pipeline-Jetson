# Jetson Moondream VLM service with CUDA GPU acceleration for JetPack 6.2.1 (L4T 36.4.4)
FROM nvcr.io/nvidia/l4t-cuda:12.6.11-runtime

# Prevent interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

# Set working directory
WORKDIR /app

# Install essential system dependencies (Ubuntu 22.04 has proper libffi8 support)
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    libffi8 \
    git \
    python3-opencv \
    libopencv-dev \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app && \
    mkdir -p /home/appuser/.cache/huggingface && \
    chown -R appuser:appuser /home/appuser/.cache

# L4T containers come with optimized OpenCV pre-installed

# Upgrade pip and clear any cache issues
RUN pip3 install --upgrade pip setuptools wheel

# Copy requirements and install Python dependencies
COPY containers/requirements-l4t-minimal.txt .
RUN pip3 install --no-cache-dir --timeout 300 --retries 3 -r requirements-l4t-minimal.txt

# Install transformers for Moondream VLM inference (Ubuntu 22.04 Python 3.10+ supports modern typing)
RUN pip3 install --no-cache-dir transformers==4.45.0 torch torchvision && \
    echo "✅ Transformers installed successfully" || \
    (echo "❌ Failed to install transformers, Moondream will run in mock mode" && exit 1)

# Copy application code
COPY services/ ./services/
COPY scripts/ ./scripts/
COPY env.example .env

# Create models directory and set up HuggingFace cache (models will be bind-mounted at runtime)
RUN mkdir -p /app/models/moondream && \
    chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Set HuggingFace cache directory
ENV HF_HOME=/home/appuser/.cache/huggingface
ENV TRANSFORMERS_CACHE=/home/appuser/.cache/huggingface

# Expose any necessary ports (none for Moondream service)

# Run the Moondream service (OpenCV patch as fallback if needed)
CMD ["python3", "services/native/moondream_native.py"]
